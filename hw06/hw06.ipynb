{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6: Hypothesis Testing and Permutation Testing\n",
    "\n",
    "## Due Tuesday, November 26th at 11:59PM\n",
    "\n",
    "Welcome to Homework 6, the last homework of the quarter! This homework covers hypothesis testing ([CIT 11](https://inferentialthinking.com/chapters/11/Testing_Hypotheses.html)) and permutation testing ([CIT 12](https://inferentialthinking.com/chapters/12/Comparing_Two_Samples.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "You are given six slip days throughout the quarter to extend deadlines. See the syllabus for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "**Important**: For homeworks, the `otter` tests don't usually tell you that your answer is correct. More often, they help catch careless mistakes. It's up to you to ensure that your answer is correct. If you're not sure, ask someone (not for the answer, but for some guidance about your approach). These are great questions for office hours (see the schedule on the [Calendar](https://dsc10.com/calendar)) or Ed. Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell, but do make sure to run it\n",
    "import babypandas as bpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Was it by Random Chansey? üé≤\n",
    "\n",
    "<img src='images/chansey.png' width='250'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You recently decided to buy the video game *Pok√©mon Yellow* from someone on Ebay. The seller tells you that they've modified the game so that the probabilities of encountering certain Pok√©mon in certain locations have been altered. However, the seller doesn't tell you which specific locations have had their probability models changed and what they've been changed to.\n",
    "\n",
    "As you are playing *Pok√©mon Yellow*, you arrive at the Safari Zone, one of the most iconic locations in the game. You're curious as to your chances of encountering your favorite Pok√©mon, Chansey, in this location. You go onto [Bulbapedia](https://bulbapedia.bulbagarden.net/wiki/Kanto_Safari_Zone#Area_1) to find the probability model for this location, and you discover that for each Pok√©mon encounter in the Safari Zone, there is a 4% chance of encountering Chansey. \n",
    "\n",
    "After a few hours of gameplay in the Safari Zone, you have encountered Chansey **48 times out of 821 total Pok√©mon encounters**, which is almost 6% of the time! You start to suspect that the Safari Zone may have been one of the locations in which the previous owner of the game changed the probability model.\n",
    "\n",
    "To test this, you decide to run a hypothesis test with the following hypotheses:\n",
    "\n",
    "- **Null Hypothesis**: In your copy of *Pok√©mon Yellow*, the probability of encountering Chansey at each Pok√©mon encounter in the Safari Zone is 4%. \n",
    "\n",
    "- **Alternative Hypothesis**: In your copy of *Pok√©mon Yellow*, the probability of encountering Chansey at each Pok√©mon encounter in the Safari Zone is greater than 4%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** Complete the implementation of the function `one_simulation`, which has no arguments. It should randomly generate 821 Pok√©mon encounters in the Safari Zone and return the **proportion** of encountered Pok√©mon that were Chansey. \n",
    "\n",
    "***Hint:*** Use `np.random.multinomial`. You don't need a `for`-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03654080389768575"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_simulation():\n",
    "    probabilities = [0.04, 0.96]\n",
    "    encounter = np.random.multinomial(821, probabilities)\n",
    "    \n",
    "    chansey_count = encounter[0]\n",
    "    chansey_prop = chansey_count / 821\n",
    "    \n",
    "    return chansey_prop\n",
    "    \n",
    "one_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1_1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1_1 results: All test cases passed!"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.** The test statistic for our hypothesis test will be the difference between the proportion of Chansey encounters in a given sample of 821 Safari Zone encounters and the expected proportion of Chansey encounters, i.e.\n",
    "\n",
    "$$\\text{test statistic} = \\text{proportion of Chansey encounters in sample} - 0.04$$\n",
    "\n",
    "\n",
    "Let's conduct 10,000 simulations. Create an array named `proportion_diffs` containing 10,000 simulated values of the test statistic described above. Utilize the function created in the previous question to perform this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "proportion_diffs = []\n",
    "\n",
    "for i in range(10000):\n",
    "    simulated_prop = one_simulation()\n",
    "    test_statistic = simulated_prop - 0.04\n",
    "    proportion_diffs.append(test_statistic)\n",
    "    \n",
    "proportion_diffs = np.array(proportion_diffs)\n",
    "\n",
    "# Visualize with a histogram. Don't change anything below.\n",
    "bpd.DataFrame().assign(proportion_differences=proportion_diffs).plot(kind='hist', bins=20, density=True, ec='w', figsize=(10, 5));\n",
    "plt.axvline(x=(48 / 821 - 0.04), color='black', linewidth=4, label='observed statistic')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1_2</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1_2 results: All test cases passed!"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.** Calculate the p-value for this hypothesis test, and assign the result to `safari_zone_p`.\n",
    "\n",
    "***Hint:*** Do large values of our test statistic favor the alternative hypothesis, or do small values of our test statistic favor the alternative hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0072"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_proportion = 48 / 821\n",
    "observed_test_statistic = observed_proportion - 0.04\n",
    "\n",
    "safari_zone_p = np.count_nonzero(proportion_diffs >= observed_test_statistic) / len(proportion_diffs)\n",
    "safari_zone_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1_3</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1_3 results: All test cases passed!"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4.** Using the standard p-value cutoff of 0.05, what can we conclude from our hypothesis test? Assign either 1, 2, 3, or 4 to the variable `safari_zone_conclusion`, corresponding to the best conclusion.\n",
    "   \n",
    "   1. We reject the null hypothesis. There is not enough evidence to say that the observed data is inconsistent with the model.\n",
    "   1. We reject the null hypothesis. The observed data is inconsistent with the model.\n",
    "   1. We accept the null hypothesis. The observed data is consistent with the model.\n",
    "   1. We fail to reject the null hypothesis. There is not enough evidence to say that the observed data is inconsistent with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "safari_zone_conclusion = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1_4</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1_4 results: All test cases passed!"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5.** In this question, we chose as our test statistic the proportion of Chansey encounters in the Safari Zone minus 0.04. But this is not the only statistic we could have chosen; there are many that could have worked here. \n",
    "\n",
    "From the options below, choose the test statistic that would **not** have worked for this hypothesis test, and assign 1, 2, 3, or 4 to the variable `bad_choice`.\n",
    "\n",
    "1. The number of Chansey encounters out of 821 enounters in the Safari Zone.\n",
    "1. The proportion of Chansey encounters in the Safari Zone.\n",
    "1. 0.04 minus the proportion of Chansey encounters in the Safari Zone.\n",
    "1. The absolute difference between 0.04 and the proportion of Chansey encounters in the Safari Zone.\n",
    "\n",
    "***Hint:*** Our goal is to find a test statistic that will help us determine whether we encounter Chansey **more** often than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_choice = 4\n",
    "bad_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1_5</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1_5 results: All test cases passed!"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Let's Roll üç£üç•ü•¢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As some of you may know, [The Bistro](https://hdh-web.ucsd.edu/dining/apps/diningservices/Restaurants/Venue_V3?locId=27&subLoc=00&locDetID=13&dayNum=0) is a popular specialty dining hall on campus located in Seventh College, which serves many types of sushi rolls. Our DSC 10 tutor, Daniel, is a big fan of The Bistro and spends a lot of time there. He proposes the following probability distribution for how frequently each type of sushi roll is ordered, based on his own observations. Note that the sum of the estimated probabilities is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Type | Daniel's Estimated Probability|\n",
    "| --- | --- |\n",
    "| Cucumber Avocado Roll | $0.08$ |\n",
    "| Seared Tuna Roll | $0.09$ |\n",
    "| Spicy Tuna Roll | $0.08$ |\n",
    "| Horizon Roll | $0.11$ |\n",
    "| The OC Roll | $0.15$ |\n",
    "| Rainbow Roll | $0.12$ |\n",
    "| Sun God Roll| $0.16$ |\n",
    "| Dragon Roll|$0.09$|\n",
    "| Crunchy Roll| $0.12$|\n",
    "\n",
    "We'll store this **proposed** distribution in an array, in the order shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08, 0.09, 0.08, 0.11, 0.15, 0.12, 0.16, 0.09, 0.12])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just run this cell, do not change it!\n",
    "proposed_dist = np.array([0.08, 0.09, 0.08, 0.11, 0.15, 0.12, 0.16, 0.09, 0.12])\n",
    "proposed_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the validity of Daniel's model, you collect data directly from The Bistro. You learn that their last 1,000 sushi orders were as follows:\n",
    "- 85 `'Cucumber Avocado Roll'`\n",
    "- 83 `'Seared Tuna Roll'`\n",
    "- 90 `'Spicy Tuna Roll'`\n",
    "- 104 `'Horizon Roll'`\n",
    "- 162 `'The OC Roll'`\n",
    "- 112 `'Rainbow Roll'`\n",
    "- 145 `'Sun God Roll`\n",
    "- 115 `'Dragon Roll` \n",
    "- 104 `'Crunchy Roll`\n",
    "\n",
    "You then calculate the **observed** distribution using the data you collected and store it in an array as well (in the same order as before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.085, 0.083, 0.09 , 0.104, 0.162, 0.112, 0.145, 0.115, 0.104])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just run this cell, do not change it!\n",
    "observed_dist = np.array([85, 83, 90, 104, 162, 112, 145, 115, 104]) / 1000\n",
    "observed_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `observed_dist` is not identical to `proposed_dist`, it's still possible that Daniel's model is plausible, and that the differences are simply due to random chance. Let's run a hypothesis test to investigate further, using the following hypotheses: \n",
    "\n",
    "- **Null Hypothesis**: Sushi orders at The Bistro are randomly drawn from the distribution `proposed_dist`.\n",
    "\n",
    "- **Alternative Hypothesis**: Sushi orders at The Bistro are _not_ drawn randomly from the distribution `proposed_dist`.\n",
    "\n",
    "Note that this hypothesis test involves nine proportions, one for each type of sushi.\n",
    "\n",
    "**Question 2.1.**  Which of the following is **not** a reasonable choice of test statistic for this hypothesis test? Assign 1, 2, or 3 to the variable `unreasonable_test_statistic`. \n",
    "1. The sum of the absolute difference between the proposed distribution (Daniel's expected proportion of types) and the observed distribution (actual proportion of types).\n",
    "1. The absolute difference between the sum of the proposed distribution (Daniel's expected proportion of types) and the sum of the observed distribution (actual proportion of types).\n",
    "1. Among all nine sushi types, the largest absolute difference between Daniel's expected proportion and the actual proportion of sushi of that type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unreasonable_test_statistic = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2_1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2_1 results: All test cases passed!"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** We'll use the TVD, i.e. **total variation distance**, as our test statistic. Below, complete the implementation of the function `total_variation_distance`, which takes as input two distributions (stored as arrays) and returns the total variation distance between those distributions.\n",
    "\n",
    "Then, use the function `total_variation_distance` to determine the TVD between the type distribution proposed by Daniel and the observed distribution of types. Assign this TVD to `observed_tvd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05200000000000001"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def total_variation_distance(first_distrib, second_distrib):\n",
    "    '''Computes the total variation distance between two distributions.'''\n",
    "    abs_differences = np.abs(first_distrib - second_distrib)\n",
    "    \n",
    "    tvd = 0.5 * np.sum(abs_differences) # sum of abs differences and divide by two\n",
    "    return tvd\n",
    "\n",
    "observed_tvd = total_variation_distance(proposed_dist, observed_dist)\n",
    "observed_tvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2_2</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2_2 results: All test cases passed!"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** Now, we'll calculate 3,000 simulated TVDs to see what a typical TVD between the proposed distribution and a simulated distribution would look like if Daniel's model were accurate. Since our real-life data includes 1000 sushi orders, in each trial of the simulation, we'll:\n",
    "- draw 1000 sushi orders at random from Daniel's proposed distribution, then \n",
    "- calculate the TVD between **Daniel's proposed type distribution** and the **type distribution from the simulated sample**. \n",
    "\n",
    "Store these 3,000 simulated TVDs in an array called `simulated_tvds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulated_tvds = []\n",
    "\n",
    "for i in range(3000):\n",
    "    simulated_counts = np.random.multinomial(1000, proposed_dist)\n",
    "    \n",
    "    simulated_proportions = simulated_counts / 1000\n",
    "\n",
    "    tvd = total_variation_distance(proposed_dist, simulated_proportions)\n",
    "\n",
    "    simulated_tvds.append(tvd)\n",
    "\n",
    "simulated_tvds = np.array(simulated_tvds)\n",
    "\n",
    "# Visualize the distribution of TVDs with a histogram\n",
    "bpd.DataFrame().assign(simulated_tvds=simulated_tvds).plot(kind='hist', density=True, ec='w', figsize=(10, 5));\n",
    "plt.axvline(x=observed_tvd, color='black', linewidth=4, label='observed TVD')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2_3</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2_3 results: All test cases passed!"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4.** Now, determine the p-value for our test by finding the proportion of times in our simulation that we saw a TVD greater than or equal to our observed TVD. Assign your result to `sushi_p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048666666666666664"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sushi_p = np.count_nonzero(simulated_tvds >= observed_tvd) / len(simulated_tvds)\n",
    "sushi_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2_4</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2_4 results: All test cases passed!"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5.** Using the p-value cutoff of 0.01, what can we conclude from our hypothesis test? Assign either 1, 2, 3, or 4 to the variable `sushi_conclusion`, corresponding to the best conclusion.\n",
    "   \n",
    "   1. We accept the null hypothesis. The observed data is consistent with the model.\n",
    "   1. We reject the null hypothesis. There is not enough evidence to say if the observed data is consistent with the model.\n",
    "   1. We reject the null hypothesis. The observed data is inconsistent with the model.\n",
    "   1. We fail to reject the null hypothesis. There is not enough evidence to say that the observed data is inconsistent with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sushi_conclusion = 4\n",
    "sushi_conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2_5</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2_5 results: All test cases passed!"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chocolate üç´üòã\n",
    "<img src='images/chocolate_bars.png' width='1000'>\n",
    "\n",
    "Chocolate is a well-loved treat that many enjoy, but some people take their chocolate very seriously. [The Manhattan Chocolate Society](https://flavorsofcacao.com/mcs_index.html) is an invitation-only society founded to taste and review chocolate bars from around the world. The [Flavors of Cacao database](https://flavorsofcacao.com/index.html) was born from tastings done by this exclusive society, and it contains reviews of almost 2,700 different dark chocolate bars. Which dark chocolate bars do these connoisseurs consider to be the best? Let's find out!\n",
    "\n",
    "Run the next cell to load in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company (Manufacturer)</th>\n",
       "      <th>Company Location</th>\n",
       "      <th>Review Date</th>\n",
       "      <th>Country of Bean Origin</th>\n",
       "      <th>Specific Bean Origin or Bar Name</th>\n",
       "      <th>Cocoa Percent</th>\n",
       "      <th>Ingredients</th>\n",
       "      <th>Characteristics</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5150</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>2021</td>\n",
       "      <td>India</td>\n",
       "      <td>Anamalai, batch 1</td>\n",
       "      <td>68%</td>\n",
       "      <td>3- B,S,C</td>\n",
       "      <td>milk brownie, macadamia,chewy</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5150</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>2021</td>\n",
       "      <td>Uganda</td>\n",
       "      <td>Semuliki Forest, batch 1</td>\n",
       "      <td>80%</td>\n",
       "      <td>3- B,S,C</td>\n",
       "      <td>mildly bitter, basic cocoa, fatty</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5150</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fiji</td>\n",
       "      <td>Matasawalevu, batch 1</td>\n",
       "      <td>68%</td>\n",
       "      <td>3- B,S,C</td>\n",
       "      <td>chewy, off, rubbery</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5150</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>2021</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>Sur del Lago, batch 1</td>\n",
       "      <td>72%</td>\n",
       "      <td>3- B,S,C</td>\n",
       "      <td>fatty, earthy, moss, nutty,chalky</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5150</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>2019</td>\n",
       "      <td>Madagascar</td>\n",
       "      <td>Bejofo Estate, batch 1</td>\n",
       "      <td>76%</td>\n",
       "      <td>3- B,S,C</td>\n",
       "      <td>cocoa, blackberry, full body</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2011</td>\n",
       "      <td>Peru</td>\n",
       "      <td>Peru</td>\n",
       "      <td>70%</td>\n",
       "      <td>4- B,S*,C,Sa</td>\n",
       "      <td>creamy, fatty, mild nutty</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2011</td>\n",
       "      <td>India</td>\n",
       "      <td>Kerala State</td>\n",
       "      <td>65%</td>\n",
       "      <td>4- B,S*,C,Sa</td>\n",
       "      <td>creamy, masculine, earthy</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2011</td>\n",
       "      <td>India</td>\n",
       "      <td>Kerala State</td>\n",
       "      <td>62%</td>\n",
       "      <td>4- B,S*,C,Sa</td>\n",
       "      <td>oily, subdued, caramel, salt</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2011</td>\n",
       "      <td>Congo</td>\n",
       "      <td>Congo</td>\n",
       "      <td>65%</td>\n",
       "      <td>4- B,S*,C,Sa</td>\n",
       "      <td>dairy, salt, caramel</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2010</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Brazil, Mitzi Blue</td>\n",
       "      <td>65%</td>\n",
       "      <td>4- B,S*,C,Sa</td>\n",
       "      <td>woody, butterscotch</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2693 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company (Manufacturer) Company Location  Review Date  \\\n",
       "0                      5150           U.S.A.         2021   \n",
       "1                      5150           U.S.A.         2021   \n",
       "2                      5150           U.S.A.         2021   \n",
       "3                      5150           U.S.A.         2021   \n",
       "4                      5150           U.S.A.         2019   \n",
       "...                     ...              ...          ...   \n",
       "2688                 Zotter          Austria         2011   \n",
       "2689                 Zotter          Austria         2011   \n",
       "2690                 Zotter          Austria         2011   \n",
       "2691                 Zotter          Austria         2011   \n",
       "2692                 Zotter          Austria         2010   \n",
       "\n",
       "     Country of Bean Origin Specific Bean Origin or Bar Name Cocoa Percent  \\\n",
       "0                     India                Anamalai, batch 1           68%   \n",
       "1                    Uganda         Semuliki Forest, batch 1           80%   \n",
       "2                      Fiji            Matasawalevu, batch 1           68%   \n",
       "3                 Venezuela            Sur del Lago, batch 1           72%   \n",
       "4                Madagascar           Bejofo Estate, batch 1           76%   \n",
       "...                     ...                              ...           ...   \n",
       "2688                   Peru                             Peru           70%   \n",
       "2689                  India                     Kerala State           65%   \n",
       "2690                  India                     Kerala State           62%   \n",
       "2691                  Congo                            Congo           65%   \n",
       "2692                 Brazil               Brazil, Mitzi Blue           65%   \n",
       "\n",
       "       Ingredients                    Characteristics  Rating  \n",
       "0         3- B,S,C      milk brownie, macadamia,chewy    3.50  \n",
       "1         3- B,S,C  mildly bitter, basic cocoa, fatty    3.25  \n",
       "2         3- B,S,C                chewy, off, rubbery    3.00  \n",
       "3         3- B,S,C  fatty, earthy, moss, nutty,chalky    3.00  \n",
       "4         3- B,S,C       cocoa, blackberry, full body    3.75  \n",
       "...            ...                                ...     ...  \n",
       "2688  4- B,S*,C,Sa          creamy, fatty, mild nutty    3.75  \n",
       "2689  4- B,S*,C,Sa          creamy, masculine, earthy    3.50  \n",
       "2690  4- B,S*,C,Sa       oily, subdued, caramel, salt    3.25  \n",
       "2691  4- B,S*,C,Sa               dairy, salt, caramel    3.00  \n",
       "2692  4- B,S*,C,Sa                woody, butterscotch    3.00  \n",
       "\n",
       "[2693 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choco = bpd.read_csv('data/chocolate.csv')\n",
    "choco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will primarily be working with the `'Characteristics'` and `'Rating'` columns. The `'Rating'` column contains a score from 1 to 5. According to Flavors of Cacao, each rating can be interpreted as follows:\n",
    "\n",
    "| Rating | Meaning |\n",
    "| ------ | ------- |\n",
    "| 4.0 - 5.0  | Outstanding |\n",
    "| 3.5 - 3.9  | Highly Recommended |\n",
    "| 3.0 - 3.49 | Recommended |\n",
    "| 2.0 - 2.9  | Disappointing |\n",
    "| 1.0 - 1.9  | Unpleasant |\n",
    "\n",
    "Ratings are determined by a combination of factors including flavor, texture, and \"aftermelt\", or the lingering experience after the chocolate has melted in your mouth.\n",
    "\n",
    "The `'Characteristics'` column contains the *most memorable characteristics* of each chocolate bar. Each bar may have several memorable characteristics, separated by a comma. For example, the chocolate bar at the last index of the DataFrame was memorable for its woody flavor and butterscotch notes.\n",
    "\n",
    "Compared to other types of chocolate, dark chocolate tends to be less sweet. However, quite a few of the chocolate bars in the DataFrame above were memorable for being sweet. How do sweet dark chocolate bars get rated relative to non-sweet dark chocolate bars? In this section, we will explore whether the ratings for sweet chocolate bars come from the same distribution as non-sweet chocolate bars. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.** Complete the implementation of the function `label_sweet`, which takes in a string of characteristics associated with a single row of `choco` and returns one of two strings. If `'sweet'` is among these characteristics, then the function should return `'Sweet'`, otherwise it should return `'Not Sweet'`.\n",
    "\n",
    "Once you've done that, use your function to help you create a new DataFrame named `labeled` that has all the same columns as `choco`, in the same order, with an additional column named `'Sweetness'` that contains whether the chocolate bar is characterized as sweet. The `'Sweetness'` column should contain only two distinct values: `'Sweet'` and `'Not Sweet'`.\n",
    "\n",
    "***Note:*** Some chocolate bars may have characteristics where `'sweet'` is contained within a word, such as `'bittersweet'`. For this question, we only want to identify bars where a characteristic is `'sweet'` itself. For example, `label_sweet('nutty, bittersweet, chalky')` should evaluate to `'Not Sweet'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company (Manufacturer)</th>\n",
       "      <th>Company Location</th>\n",
       "      <th>Review Date</th>\n",
       "      <th>Country of Bean Origin</th>\n",
       "      <th>Specific Bean Origin or Bar Name</th>\n",
       "      <th>Cocoa Percent</th>\n",
       "      <th>Ingredients</th>\n",
       "      <th>Characteristics</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Sweetness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5150</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>2021</td>\n",
       "      <td>India</td>\n",
       "      <td>Anamalai, batch 1</td>\n",
       "      <td>68%</td>\n",
       "      <td>3- B,S,C</td>\n",
       "      <td>milk brownie, macadamia,chewy</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Not Sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5150</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>2021</td>\n",
       "      <td>Uganda</td>\n",
       "      <td>Semuliki Forest, batch 1</td>\n",
       "      <td>80%</td>\n",
       "      <td>3- B,S,C</td>\n",
       "      <td>mildly bitter, basic cocoa, fatty</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Not Sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5150</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fiji</td>\n",
       "      <td>Matasawalevu, batch 1</td>\n",
       "      <td>68%</td>\n",
       "      <td>3- B,S,C</td>\n",
       "      <td>chewy, off, rubbery</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Not Sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5150</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>2021</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>Sur del Lago, batch 1</td>\n",
       "      <td>72%</td>\n",
       "      <td>3- B,S,C</td>\n",
       "      <td>fatty, earthy, moss, nutty,chalky</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Not Sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5150</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>2019</td>\n",
       "      <td>Madagascar</td>\n",
       "      <td>Bejofo Estate, batch 1</td>\n",
       "      <td>76%</td>\n",
       "      <td>3- B,S,C</td>\n",
       "      <td>cocoa, blackberry, full body</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Not Sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2011</td>\n",
       "      <td>Peru</td>\n",
       "      <td>Peru</td>\n",
       "      <td>70%</td>\n",
       "      <td>4- B,S*,C,Sa</td>\n",
       "      <td>creamy, fatty, mild nutty</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Not Sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2011</td>\n",
       "      <td>India</td>\n",
       "      <td>Kerala State</td>\n",
       "      <td>65%</td>\n",
       "      <td>4- B,S*,C,Sa</td>\n",
       "      <td>creamy, masculine, earthy</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Not Sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2011</td>\n",
       "      <td>India</td>\n",
       "      <td>Kerala State</td>\n",
       "      <td>62%</td>\n",
       "      <td>4- B,S*,C,Sa</td>\n",
       "      <td>oily, subdued, caramel, salt</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Not Sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2011</td>\n",
       "      <td>Congo</td>\n",
       "      <td>Congo</td>\n",
       "      <td>65%</td>\n",
       "      <td>4- B,S*,C,Sa</td>\n",
       "      <td>dairy, salt, caramel</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Not Sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2010</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Brazil, Mitzi Blue</td>\n",
       "      <td>65%</td>\n",
       "      <td>4- B,S*,C,Sa</td>\n",
       "      <td>woody, butterscotch</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Not Sweet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2693 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company (Manufacturer) Company Location  Review Date  \\\n",
       "0                      5150           U.S.A.         2021   \n",
       "1                      5150           U.S.A.         2021   \n",
       "2                      5150           U.S.A.         2021   \n",
       "3                      5150           U.S.A.         2021   \n",
       "4                      5150           U.S.A.         2019   \n",
       "...                     ...              ...          ...   \n",
       "2688                 Zotter          Austria         2011   \n",
       "2689                 Zotter          Austria         2011   \n",
       "2690                 Zotter          Austria         2011   \n",
       "2691                 Zotter          Austria         2011   \n",
       "2692                 Zotter          Austria         2010   \n",
       "\n",
       "     Country of Bean Origin Specific Bean Origin or Bar Name Cocoa Percent  \\\n",
       "0                     India                Anamalai, batch 1           68%   \n",
       "1                    Uganda         Semuliki Forest, batch 1           80%   \n",
       "2                      Fiji            Matasawalevu, batch 1           68%   \n",
       "3                 Venezuela            Sur del Lago, batch 1           72%   \n",
       "4                Madagascar           Bejofo Estate, batch 1           76%   \n",
       "...                     ...                              ...           ...   \n",
       "2688                   Peru                             Peru           70%   \n",
       "2689                  India                     Kerala State           65%   \n",
       "2690                  India                     Kerala State           62%   \n",
       "2691                  Congo                            Congo           65%   \n",
       "2692                 Brazil               Brazil, Mitzi Blue           65%   \n",
       "\n",
       "       Ingredients                    Characteristics  Rating  Sweetness  \n",
       "0         3- B,S,C      milk brownie, macadamia,chewy    3.50  Not Sweet  \n",
       "1         3- B,S,C  mildly bitter, basic cocoa, fatty    3.25  Not Sweet  \n",
       "2         3- B,S,C                chewy, off, rubbery    3.00  Not Sweet  \n",
       "3         3- B,S,C  fatty, earthy, moss, nutty,chalky    3.00  Not Sweet  \n",
       "4         3- B,S,C       cocoa, blackberry, full body    3.75  Not Sweet  \n",
       "...            ...                                ...     ...        ...  \n",
       "2688  4- B,S*,C,Sa          creamy, fatty, mild nutty    3.75  Not Sweet  \n",
       "2689  4- B,S*,C,Sa          creamy, masculine, earthy    3.50  Not Sweet  \n",
       "2690  4- B,S*,C,Sa       oily, subdued, caramel, salt    3.25  Not Sweet  \n",
       "2691  4- B,S*,C,Sa               dairy, salt, caramel    3.00  Not Sweet  \n",
       "2692  4- B,S*,C,Sa                woody, butterscotch    3.00  Not Sweet  \n",
       "\n",
       "[2693 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_sweet(characteristics): \n",
    "    filter = characteristics.split(', ')\n",
    "    \n",
    "    if 'sweet' in filter:\n",
    "        return 'Sweet'\n",
    "    else:\n",
    "        return 'Not Sweet'\n",
    "    \n",
    "labeled = choco.assign(Sweetness = choco.get('Characteristics').apply(label_sweet))\n",
    "labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3_1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3_1 results: All test cases passed!"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2.** Assign `chocolate` to a DataFrame with only two columns, `'Sweetness'` and `'Rating'`, since these are the only relevant columns in `labeled` to answer the question we've proposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Sweet</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Sweet</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Sweet</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Sweet</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not Sweet</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>Not Sweet</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>Not Sweet</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>Not Sweet</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>Not Sweet</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>Not Sweet</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2693 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sweetness  Rating\n",
       "0     Not Sweet    3.50\n",
       "1     Not Sweet    3.25\n",
       "2     Not Sweet    3.00\n",
       "3     Not Sweet    3.00\n",
       "4     Not Sweet    3.75\n",
       "...         ...     ...\n",
       "2688  Not Sweet    3.75\n",
       "2689  Not Sweet    3.50\n",
       "2690  Not Sweet    3.25\n",
       "2691  Not Sweet    3.00\n",
       "2692  Not Sweet    3.00\n",
       "\n",
       "[2693 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chocolate = labeled.get([\"Sweetness\", \"Rating\"])\n",
    "chocolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3_2</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3_2 results: All test cases passed!"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3.** Using the DataFrame `chocolate`, calculate the difference between the **mean** `'Rating'` of sweet chocolate bars and non-sweet chocolate bars. Assign your answer to `observed_difference`.\n",
    "\n",
    "$$\\text{observed difference} = \\text{mean rating of sweet chocolate bars} - \\text{mean rating of non-sweet chocolate bars}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.16271384367771047"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sweet = chocolate[chocolate.get('Sweetness') == 'Sweet'].get('Rating').mean()\n",
    "mean_non_sweet = chocolate[chocolate.get('Sweetness') == 'Not Sweet'].get('Rating').mean()\n",
    "\n",
    "observed_difference = mean_sweet - mean_non_sweet\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3_3</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3_3 results: All test cases passed!"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4.** What does the number you obtained for `observed_difference` mean? Assign `interpretation` to 1, 2, 3, 4, 5 or 6 corresponding to the best explanation below.\n",
    "\n",
    "1. In our sample, the mean rating for sweet chocolate bars is higher than the mean rating for non-sweet chocolate bars by about 16 percent.\n",
    "1. In our sample, the mean rating for sweet chocolate bars is higher than the mean rating for non-sweet chocolate bars by about 0.16 percent.\n",
    "1. In our sample, the mean rating for sweet chocolate bars is higher than the mean rating for non-sweet chocolate bars by about 0.16 rating points.\n",
    "1. In our sample, the mean rating for sweet chocolate bars is lower than the mean rating for non-sweet chocolate bars by about 16 percent.\n",
    "1. In our sample, the mean rating for sweet chocolate bars is lower than the mean rating for non-sweet chocolate bars by about 0.16 percent.\n",
    "1. In our sample, the mean rating for sweet chocolate bars is lower than the mean rating for non-sweet chocolate bars by about 0.16 rating points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3_4</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3_4 results: All test cases passed!"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5.** Now we want to conduct a **permutation test** to see if sweet chocolate bars actually have a lower rating on average than non-sweet chocolate bars, or whether this was just observed in our sample by random chance.\n",
    "\n",
    "- **Null Hypothesis**: The ratings of sweet chocolate bars and non-sweet chocolate bars come from the same distribution.  \n",
    "- **Alternative Hypothesis**: The ratings of sweet chocolate bars are lower on average than the ratings of non-sweet chocolate bars.\n",
    "\n",
    "Run a permutation test to see if the `observed_difference` you calculated in Question 3.3 is actually a statistically significant difference. Simulate 1000 values of the test statistic by shuffling the `'Sweetness'` column of `chocolate` and calculating the difference in mean rating between the two groups determined by the shuffling (again, in the order sweet minus non-sweet). Store your 1000 differences in the `differences` array. \n",
    "\n",
    "***Hint:*** It's a good idea to simulate one value of the test statistic before putting everything in a for-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02376668, -0.01277086,  0.00822116,  0.01721774,  0.02221584,\n",
       "        0.0002242 ,  0.040209  , -0.0297644 , -0.01377048,  0.00322306])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "differences = []\n",
    "\n",
    "for i in range(1000):\n",
    "    sweetness = np.random.permutation(chocolate.get('Sweetness'))\n",
    "\n",
    "    shuffled = chocolate.assign(Sweetness=sweetness)\n",
    "\n",
    "    mean_sweet = shuffled[shuffled.get('Sweetness') == 'Sweet'].get('Rating').mean()\n",
    "    mean_non_sweet = shuffled[shuffled.get('Sweetness') == 'Not Sweet'].get('Rating').mean()\n",
    "\n",
    "    difference = mean_sweet - mean_non_sweet\n",
    "\n",
    "    differences.append(difference)\n",
    "\n",
    "differences = np.array(differences)\n",
    "\n",
    "# Just display the first ten differences.\n",
    "differences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3_5</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3_5 results: All test cases passed!"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6.** Compute a p-value for this hypothesis test and assign your answer to `chocolate_p`. To decide whether to use `<=` or `>=` in the calculation of the p-value, think about whether larger values or smaller values of our test statistic favor the alternative hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chocolate_p = np.count_nonzero(differences <= observed_difference) / len(differences)\n",
    "chocolate_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3_6</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3_6 results: All test cases passed!"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.7.** Assign the variable `chocolate_conclusion` to a **list** of all the true statements below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We accept the null hypothesis at the 0.01 significance level.\n",
    "1. We reject the null hypothesis at the 0.01 significance level.\n",
    "1. We fail to reject the null hypothesis at the 0.01 significance level.\n",
    "1. We accept the null hypothesis at the 0.05 significance level.\n",
    "1. We reject the null hypothesis at the 0.05 significance level.\n",
    "1. We fail to reject the null hypothesis at the 0.05 significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, interpret your results by setting `sweeter_is_worse` to `True` or `False`, based on the outcome of your permutation test. `True` means that sweet chocolate bars actually do have lower ratings than non-sweet bars, and `False` means they do not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "chocolate_conclusion = [2, 5]\n",
    "sweeter_is_worse = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3_7</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3_7 results: All test cases passed!"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.8.** Suppose in this question you had shuffled the `'Rating'` column instead and kept the `'Sweetness'` column in the same order. Assign `shuffled_rating` to either 1, 2, 3, or 4, corresponding to the true statement below.\n",
    "\n",
    "\n",
    "1. The new p-value from shuffling `'Rating'` would be $1 - p$, where $p$ is the old p-value from shuffling `'Sweetness'` (i.e. your answer to Question 3.6).\n",
    "1. We would need to change our null hypothesis in order to shuffle the `'Rating'` column. \n",
    "1. There would be no difference in the conclusion of the test if we had shuffled the `'Rating'` column instead.\n",
    "1. The `'Rating'` column cannot be shuffled because it contains numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_rating = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3_8</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3_8 results: All test cases passed!"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.9.** Which of the following choices best describes the purpose of shuffling one of the columns in our dataset in a permutation test? Assign `why_shuffle` to either 1, 2, 3, or 4, corresponding to the true statement below.\n",
    "\n",
    "1. Shuffling mitigates noise in our data by generating new permutations of the data.\n",
    "1. Shuffling is a special case of bootstrapping and allows us to produce interval estimates.\n",
    "1. Shuffling allows us to generate new data under the null hypothesis, which we can use in testing our hypothesis.\n",
    "1. Shuffling allows us to generate new data under the alternative hypothesis, which helps us identify when the data come from different distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "why_shuffle = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3_9</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3_9 results: All test cases passed!"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3_9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to explore the chocolate data some more to see if other characteristics are linked with higher or lower ratings! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. New York Times Mini Crossword üß©üïê\n",
    "<img src='images/nyt_mini_crossword.png' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The New York Times Mini Crossword](https://www.nytimes.com/crosswords/game/mini) is a smaller and quicker version of the traditional crossword puzzle. It features straightforward clues and is designed to be completed in a few minutes. After completing the puzzle, players have the option to send the time it took to complete the puzzle to their friends, to try to compete for the lowest time.\n",
    "\n",
    "Ciro and Athu have been playing the New York Times Mini Crossword for a couple months, often sending each other the time it takes for them to complete each puzzle. Today, Ciro's time was much faster than Athu's so he bragged that he is better than Athu at the game. Athu vehemently disagrees and thinks that they are equally skilled.\n",
    "\n",
    "Since the two of them have learned about hypothesis testing in DSC10, they decided to look at their history of times to determine if they were equally skilled or if one of them was better than the other.\n",
    "\n",
    "Let's look at all the data that they collected. Each entry in the `'Time'` column represents the amount of time it took in seconds for one person to complete the New York Times Mini Crossword on a single day. There are 25 times for Ciro and 25 times for Athu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ciro</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Athu</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ciro</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Athu</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ciro</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Athu</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ciro</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Athu</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Ciro</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Athu</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Time\n",
       "0   Ciro   108\n",
       "1   Athu   110\n",
       "2   Ciro   100\n",
       "3   Athu   109\n",
       "4   Ciro   109\n",
       "..   ...   ...\n",
       "45  Athu   110\n",
       "46  Ciro   108\n",
       "47  Athu   109\n",
       "48  Ciro   108\n",
       "49  Athu   110\n",
       "\n",
       "[50 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_cw = bpd.read_csv('data/mini-crossword.csv')\n",
    "mini_cw "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1.** Now let's address the question: how does the average time for Ciro to complete the crossword compare to Athu's average time? Create a DataFrame called `ciro` with only the rows of `mini_cw` that correspond to Ciro, and set `ciro_mean` to Ciro's mean time to complete the crossword. Similarly, create a DataFrame `athu` for Athu and compute `athu_mean`. Finally, set `observed_diff_mean`, to the difference in mean times to complete the crossword in our sample, computed as follows.\n",
    "\n",
    "$$\\text{difference} = \\text{mean time to complete the crossword for Ciro} - \\text{mean time to complete the crossword for Athu}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6000000000000085"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciro = mini_cw[mini_cw.get(\"Name\") == \"Ciro\"]\n",
    "athu = mini_cw[mini_cw.get(\"Name\") == \"Athu\"]\n",
    "ciro_mean = ciro.get(\"Time\").mean()\n",
    "athu_mean = athu.get(\"Time\").mean()\n",
    "observed_diff_mean = ciro_mean - athu_mean\n",
    "observed_diff_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4_1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q4_1 results: All test cases passed!"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you answered Question 4.1 correctly, you should have noticed a difference in the average times between Ciro and Athu. But we only have a small sample of their performance on the Mini Crossword, so it's possible that this difference is merely a result of the specific samples we happened to collect. Let's do a **hypothesis test** to find out if there's actually a difference in their abilities. We'll state our hypotheses as follows:\n",
    "\n",
    "- **Null Hypothesis**: The average time it takes to complete the New York Times Mini Crossword is the same for both Ciro and Athu. In other words, their difference in average time is equal to 0 seconds.\n",
    "\n",
    "- **Alternative Hypothesis**: The average time it takes to complete the New York Times Mini Crossword is not the same for both Ciro and Athu. In other words, the difference in average time between the two of them is not equal to 0 seconds.\n",
    "\n",
    "\n",
    "Since we are able to frame our hypothesis test as a question of whether a certain population parameter ‚Äì the difference in average times ‚Äì is equal to a specific value, we can **test our hypotheses by constructing a confidence interval** for this parameter. For a refresher on this method, refer to [CIT 13.4](https://inferentialthinking.com/chapters/13/4/Using_Confidence_Intervals.html) or the human body temperature example from [Lecture 22](https://dsc10.com/resources/lectures/lec22/lec22.html).\n",
    "\n",
    "***Note:*** We are **not** conducting a permutation test here, although that would also be a valid approach to test these hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2.** Compute 1000 **bootstrapped estimates** for the difference in average times between Ciro and Athu. As in Question 4.1, calculate the difference as Ciro minus Athu. Store your 1000 estimates in the `difference_means` array.\n",
    "\n",
    "You should generate your Ciro resamples by sampling from `ciro`, and your Athu resamples by sampling from `athu`. Do not use the combined dataset `mini_cw` for this task, otherwise you might not wind up with 25 of each!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24, -0.72, -1.68, -0.64, -0.08, -1.44, -0.12,  0.52,  1.48,\n",
       "       -0.56])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_means = []\n",
    "\n",
    "for i in range(1000):\n",
    "    bootstrap_ciro = ciro.sample(ciro.shape[0], replace=True)\n",
    "    bootstrap_athu = athu.sample(athu.shape[0], replace=True)\n",
    "    \n",
    "    bootstrap_ciro_mean = bootstrap_ciro.get(\"Time\").mean()\n",
    "    bootstrap_athu_mean = bootstrap_athu.get(\"Time\").mean()\n",
    "    \n",
    "    difference_means.append(bootstrap_ciro_mean - bootstrap_athu_mean)\n",
    "\n",
    "difference_means = np.array(difference_means)\n",
    "\n",
    "# Just display the first ten differences.\n",
    "difference_means[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4_2</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q4_2 results: All test cases passed!"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize your estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bpd.DataFrame().assign(BootstrappedDifferenceMeans = difference_means).plot(kind = 'hist', density=True, ec='w', bins=20, figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3.** Compute a 95% confidence interval for the difference in mean times (as before, in the order Ciro minus Athu). Assign the left and right endpoints of this confidence interval to `left_endpoint` and `right_endpoint` respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 95% confidence interval for the mean difference in time to complete the crossword for Ciro and Athu:\n",
      " [-2.200000, 1.361000]\n"
     ]
    }
   ],
   "source": [
    "left_endpoint = np.percentile(difference_means, 2.5)\n",
    "right_endpoint = np.percentile(difference_means, 97.5)\n",
    "\n",
    "print('Bootstrapped 95% confidence interval for the mean difference in time to complete the crossword for Ciro and Athu:\\n [{:f}, {:f}]'.format(left_endpoint, right_endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4_3</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q4_3 results: All test cases passed!"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4.** Based on the confidence interval you've created, would you reject the null hypothesis at the 0.05 significance level? Set `reject_null` to True if you would reject the null hypothesis, and False if you would not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_null = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4_4</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q4_4 results: All test cases passed!"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.5.** Consider what would happen if Ciro and Athu collected their times in minutes instead of seconds. Would your confidence interval have the same endpoints either way? Set `same_endpoints` to True or False. Would your hypothesis test still come to the same conclusion either way? Set `same_conclusion` to True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_endpoints = False\n",
    "same_conclusion = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4_5</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q4_5 results: All test cases passed!"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish Line: Almost there, but make sure to follow the steps below to submit! üèÅ\n",
    "\n",
    "**_Citations:_** Did you use any generative artificial intelligence tools to assist you on this assignment? If so, please state, for each tool you used, the name of the tool (ex. ChatGPT) and the problem(s) in this assignment where you used the tool for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">\n",
    "\n",
    "Please cite tools here.\n",
    "\n",
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You are done with Homework 6 ‚Äì the final homework of the quarter! üéâ\n",
    "\n",
    "To submit your assignment:\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "1. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "1. Run the cell below to run all tests, and make sure that they all pass.\n",
    "1. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope.\n",
    "1. Stick around while the Gradescope autograder grades your work. Make sure you see that all tests have passed on Gradescope.\n",
    "1. Check that you have a confirmation email from Gradescope and save it as proof of your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1_1 results: All test cases passed!\n",
       "\n",
       "q1_2 results: All test cases passed!\n",
       "\n",
       "q1_3 results: All test cases passed!\n",
       "\n",
       "q1_4 results: All test cases passed!\n",
       "\n",
       "q1_5 results: All test cases passed!\n",
       "\n",
       "q2_1 results: All test cases passed!\n",
       "\n",
       "q2_2 results: All test cases passed!\n",
       "\n",
       "q2_3 results: All test cases passed!\n",
       "\n",
       "q2_4 results: All test cases passed!\n",
       "\n",
       "q2_5 results: All test cases passed!\n",
       "\n",
       "q3_1 results: All test cases passed!\n",
       "\n",
       "q3_2 results: All test cases passed!\n",
       "\n",
       "q3_3 results: All test cases passed!\n",
       "\n",
       "q3_4 results: All test cases passed!\n",
       "\n",
       "q3_5 results: All test cases passed!\n",
       "\n",
       "q3_6 results: All test cases passed!\n",
       "\n",
       "q3_7 results: All test cases passed!\n",
       "\n",
       "q3_8 results: All test cases passed!\n",
       "\n",
       "q3_9 results: All test cases passed!\n",
       "\n",
       "q4_1 results: All test cases passed!\n",
       "\n",
       "q4_2 results: All test cases passed!\n",
       "\n",
       "q4_3 results: All test cases passed!\n",
       "\n",
       "q4_4 results: All test cases passed!\n",
       "\n",
       "q4_5 results: All test cases passed!"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
